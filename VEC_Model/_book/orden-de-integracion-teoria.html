<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Código Tesis</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Código Tesis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Código Tesis" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Omar Díaz Landa">


<meta name="date" content="2019-03-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="datos.html">
<link rel="next" href="orden-integracion-pib-a-precios-corrientes.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Tesis Omar Díaz Landa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisitos</a></li>
<li class="chapter" data-level="2" data-path="datos.html"><a href="datos.html"><i class="fa fa-check"></i><b>2</b> Lectura de datos</a><ul>
<li class="chapter" data-level="2.1" data-path="datos.html"><a href="datos.html#graficamos-las-series-de-datos"><i class="fa fa-check"></i><b>2.1</b> Graficamos las series de datos</a><ul>
<li class="chapter" data-level="2.1.1" data-path="datos.html"><a href="datos.html#producto-interno-bruto"><i class="fa fa-check"></i><b>2.1.1</b> Producto Interno Bruto</a></li>
<li class="chapter" data-level="2.1.2" data-path="datos.html"><a href="datos.html#recaudacion-fiscal"><i class="fa fa-check"></i><b>2.1.2</b> Recaudación Fiscal</a></li>
<li class="chapter" data-level="2.1.3" data-path="datos.html"><a href="datos.html#gasto-en-salud-publica"><i class="fa fa-check"></i><b>2.1.3</b> Gasto en Salud Pública</a></li>
<li class="chapter" data-level="2.1.4" data-path="datos.html"><a href="datos.html#gasto-en-educacion-publica"><i class="fa fa-check"></i><b>2.1.4</b> Gasto en Educación Pública</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="orden-de-integracion-teoria.html"><a href="orden-de-integracion-teoria.html"><i class="fa fa-check"></i><b>3</b> Orden de Integración (Teoría)</a></li>
<li class="chapter" data-level="4" data-path="orden-integracion-pib-a-precios-corrientes.html"><a href="orden-integracion-pib-a-precios-corrientes.html"><i class="fa fa-check"></i><b>4</b> Orden Integración PIB a precios corrientes</a></li>
<li class="chapter" data-level="5" data-path="orden-de-integracion-lnpib-a-precios-corrientes.html"><a href="orden-de-integracion-lnpib-a-precios-corrientes.html"><i class="fa fa-check"></i><b>5</b> Orden de Integración ln(PIB) a precios corrientes</a></li>
<li class="chapter" data-level="6" data-path="orden-integracion-de-la-serie-recaudacion-impositiva.html"><a href="orden-integracion-de-la-serie-recaudacion-impositiva.html"><i class="fa fa-check"></i><b>6</b> Orden Integración de la serie Recaudación Impositiva</a></li>
<li class="chapter" data-level="7" data-path="orden-integracion-de-la-serie-gasto-en-salud.html"><a href="orden-integracion-de-la-serie-gasto-en-salud.html"><i class="fa fa-check"></i><b>7</b> Orden Integración de la serie Gasto en Salud</a></li>
<li class="chapter" data-level="8" data-path="orden-integracion-de-la-serie-gasto-en-educacion.html"><a href="orden-integracion-de-la-serie-gasto-en-educacion.html"><i class="fa fa-check"></i><b>8</b> Orden Integración de la serie Gasto en Educación</a></li>
<li class="chapter" data-level="9" data-path="orden-integracion-de-la-serie-lnpib-a-precios-ctes.html"><a href="orden-integracion-de-la-serie-lnpib-a-precios-ctes.html"><i class="fa fa-check"></i><b>9</b> Orden Integración de la serie ln(PIB) a precios ctes</a></li>
<li class="chapter" data-level="10" data-path="cointegracion-teoria.html"><a href="cointegracion-teoria.html"><i class="fa fa-check"></i><b>10</b> Cointegración (Teoría)</a></li>
<li class="chapter" data-level="11" data-path="cointegracion-analisis.html"><a href="cointegracion-analisis.html"><i class="fa fa-check"></i><b>11</b> Cointegración (Análisis)</a><ul>
<li class="chapter" data-level="11.1" data-path="cointegracion-analisis.html"><a href="cointegracion-analisis.html#determinacion-del-rango-de-cointegracion"><i class="fa fa-check"></i><b>11.1</b> Determinación del Rango de Cointegración</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="estimacion-del-modelo.html"><a href="estimacion-del-modelo.html"><i class="fa fa-check"></i><b>12</b> Estimación del modelo</a><ul>
<li class="chapter" data-level="12.1" data-path="estimacion-del-modelo.html"><a href="estimacion-del-modelo.html#modelo-1-vecm-con-k2-lags-y-r1-relaciones-de-cointegracion"><i class="fa fa-check"></i><b>12.1</b> Modelo 1: VECM con K=2 (lags), y r=1 (relaciones de cointegración)</a></li>
<li class="chapter" data-level="12.2" data-path="estimacion-del-modelo.html"><a href="estimacion-del-modelo.html#modelo-2-vecm-con-k2-lags-y-r2-relaciones-de-cointegracion"><i class="fa fa-check"></i><b>12.2</b> Modelo 2: VECM con K=2 (lags), y r=2 (relaciones de cointegración)</a></li>
<li class="chapter" data-level="12.3" data-path="estimacion-del-modelo.html"><a href="estimacion-del-modelo.html#modelo-3-vecm-con-k3-lags-y-r1-relaciones-de-cointegracion"><i class="fa fa-check"></i><b>12.3</b> Modelo 3: VECM con K=3 (lags), y r=1 (relaciones de cointegración)</a></li>
<li class="chapter" data-level="12.4" data-path="estimacion-del-modelo.html"><a href="estimacion-del-modelo.html#modelo-4-vecm-con-k3-lags-y-r2-relaciones-de-cointegracion"><i class="fa fa-check"></i><b>12.4</b> Modelo 4: VECM con K=3 (lags), y r=2 (relaciones de cointegración)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="13" data-path="interpolacion-serie-educacion.html"><a href="interpolacion-serie-educacion.html"><i class="fa fa-check"></i><b>13</b> Interpolación Serie Educación</a><ul>
<li class="chapter" data-level="13.1" data-path="interpolacion-serie-educacion.html"><a href="interpolacion-serie-educacion.html#version-2-del-pronositico"><i class="fa fa-check"></i><b>13.1</b> version 2 del pronositico</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="Anexos.html"><a href="Anexos.html"><i class="fa fa-check"></i><b>14</b> Anexos</a><ul>
<li class="chapter" data-level="14.1" data-path="Anexos.html"><a href="Anexos.html#descripcion-de-las-series"><i class="fa fa-check"></i><b>14.1</b> Descripción de las series</a></li>
<li class="chapter" data-level="14.2" data-path="Anexos.html"><a href="Anexos.html#bibliografia"><i class="fa fa-check"></i><b>14.2</b> Bibliografia</a></li>
<li class="chapter" data-level="14.3" data-path="Anexos.html"><a href="Anexos.html#dudas"><i class="fa fa-check"></i><b>14.3</b> Dudas</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Código Tesis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="orden-de-integracion-teoria" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Orden de Integración (Teoría)</h1>
<p>En el modelo</p>
<p><span class="math display">\[ y_t = a_1y_{t-1}+\epsilon_t\]</span></p>
<p>Al restar por <span class="math inline">\(y_{t-1}\)</span> en ambos lados de la ecuación, podemos llegar a la siguiente expresión equivalente:</p>
<p><span class="math display">\[ \nabla y_t =  \gamma y_{t-1}+\epsilon_t\]</span></p>
<p>donde <span class="math inline">\(\gamma = a_1-1\)</span>. Por lo tanto, realizar la prueba de hipótesis <span class="math inline">\(a_1=1\)</span> es equivalente a probar que <span class="math inline">\(\gamma=0\)</span>. Dickey y Fuller consideran tres tipos de ecuaciones de regresión que pueden ser utilizadas para probar la presencia de raíces unitarias:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\nabla y_t = \gamma y_{t-1} + \epsilon_t\)</span></li>
<li><span class="math inline">\(\nabla y_t = a_0 + \gamma y_{t-1} + \epsilon_t\)</span></li>
<li><span class="math inline">\(\nabla y_t = a_0 + \gamma y_{t-1} + a_2t + \epsilon_t\)</span></li>
</ol>
<p>El primero de ellos es un modelo puro de caminata aleatoria, el segundo agrega un intercepto o drift y el tercero incluye tanto un drift como una tendencia lineal temporal.</p>
<p>El parámetro de interés en todas estas ecuaciones es <span class="math inline">\(\gamma\)</span>; Si <span class="math inline">\(\gamma=0\)</span> entonces la serie <span class="math inline">\(y_t\)</span> contiene una raíz unitaria. La prueba se reduce en estimar las ecuaciones anteriormente mencionadas via OLS, de tal manera que se obtenga el valor estimado del parametro <span class="math inline">\(\gamma\)</span> y su error estandar asociado. Dicho estadistico <span class="math inline">\(t\)</span> se debe comparar con sus correspondientes valores de acuerdo con las tablas creadas por Dicckey-Fuller.</p>
<p>Esta metodología se sigue para cualquiera de las tres ecuaciones enunciadas anteriormente, sin embargo, el detalle es que cambian los valores criticos de Dickey-Fuller dependiendo la ecuacion utilizada para estimar el valor del parametro <span class="math inline">\(\gamma\)</span>. Dickey-Fuller concluyeron que los valores criticos para <span class="math inline">\(\gamma=0\)</span> dependen del tipo de regresión y el tamaño de la muestra.</p>
<p>Los estadísticos <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\tau_2\)</span>, <span class="math inline">\(\tau_3\)</span> son los estadísticos apropiados para usar en las ecuaciones (1), (2) y (3) respectivamente. Los valores reportados en las tablas de Dickey-Fuller permiten al investigador determinar si aceptar o rechazar la hipótesis nula <span class="math inline">\(\gamma=0\)</span> unicamente.</p>
<p>Adicionalmente Dickey and Fuller crearon tres F-estadisticos adicionales llamados <span class="math inline">\(\phi_1,\phi_2,\phi_3\)</span> para probar pruebas de hipotesis conjuntas:</p>
<ul>
<li>El estadistico <span class="math inline">\(\phi_1\)</span> .- Emplea la ecuacion numero 2 para probar la hipotesis nula conjunta <span class="math inline">\(\gamma=a_0=0\)</span></li>
<li>El estadistico <span class="math inline">\(\phi_2\)</span> .- Emplea la ecuacion numero 3 para probar la hipotesis nula conjunta <span class="math inline">\(\gamma=a_0=a_2=0\)</span></li>
<li>El estadistico <span class="math inline">\(\phi_3\)</span> .- Emplea la ecuacion numero 3 para probar la hipotesis nula conjunta <span class="math inline">\(\gamma=a_2=0\)</span></li>
</ul>
<p>En donde los tres estadisticos se construyen igual que cualquier prueba <span class="math inline">\(F\)</span>:</p>
<p><span class="math display">\[ \phi_i = \frac{[RSS_{restricted}-RSS_{unrestricted}]r}{RSS_{unrestricted}(T-k)}\]</span> donde <span class="math inline">\(RSS\)</span> son las sumas al cuadrado de los residuales del modelo restringido vs el no restringido, <span class="math inline">\(r\)</span> es el numero de restricciones, <span class="math inline">\(T\)</span> el numero de observaciones usbales y <span class="math inline">\(k\)</span> el numero de parametros estimados en el modelo sin restricciones.</p>
<p>Por lo tanto, la hipotesis nula es que los datos fueron generados por el modelo con restricciones y la alternativa es que los datos fueron generados por el modelo sin restricciones. Si la restriccion no se cumple, la suma de los cuadrados de ambos modelos deberian ser muy similares y por lo tanto <span class="math inline">\(\phi_i\)</span> será pequeña. Asi pues, si el valor de <span class="math inline">\(\phi\)</span> es grande quiere decir que se rechaza la hipotesis nula.</p>
<p><a href="http://stats.stackexchange.com/questions/24072/interpreting-rs-ur-df-dickey-fuller-unit-root-test-results" class="uri">http://stats.stackexchange.com/questions/24072/interpreting-rs-ur-df-dickey-fuller-unit-root-test-results</a></p>
<p>Usaremos la prueba ADF sobre la serie del consumo en UK usando datos trimestrales del perido 1966:Q4-1991:Q2. La serie del consumo esta ajustada estacionalmente a precios de 1985 y expresadas en su logaritmo natural.</p>
<p>Como un primer paso, una regresión con una constante y tendencia temporal será estimada, se agregarán 3 lags a la estimación para evitar la presencia de autocorrelaciones y autocorrelaciones parciales y asegurar un proceso esférico del error. Incluir el cuarto lag resultaba ser no significativo, mientras que incluir solo dos lags no eran suficientes para alcanzar errores serialmente no correlacionados.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;Raotbl3&quot;</span>)
<span class="kw">attach</span>(Raotbl3)

lc &lt;-<span class="st"> </span><span class="kw">ts</span>(lc, <span class="dt">start=</span><span class="kw">c</span>(<span class="dv">1966</span>,<span class="dv">4</span>), <span class="dt">end=</span><span class="kw">c</span>(<span class="dv">1991</span>,<span class="dv">2</span>),<span class="dt">frequency=</span><span class="dv">4</span>)
lc.ct &lt;-<span class="st"> </span><span class="kw">ur.df</span>(lc,<span class="dt">lags=</span><span class="dv">3</span>,<span class="dt">type=</span><span class="st">&#39;trend&#39;</span>)
<span class="kw">summary</span>(lc.ct)</code></pre></div>
<pre><code>## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.044714 -0.006525  0.000129  0.006225  0.045353 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  0.7976591  0.3547775   2.248   0.0270 * 
## z.lag.1     -0.0758706  0.0338880  -2.239   0.0277 * 
## tt           0.0004915  0.0002159   2.277   0.0252 * 
## z.diff.lag1 -0.1063957  0.1006744  -1.057   0.2934   
## z.diff.lag2  0.2011373  0.1012373   1.987   0.0500 . 
## z.diff.lag3  0.2998586  0.1020548   2.938   0.0042 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01307 on 89 degrees of freedom
## Multiple R-squared:  0.1472, Adjusted R-squared:  0.09924 
## F-statistic: 3.071 on 5 and 89 DF,  p-value: 0.01325
## 
## 
## Value of test-statistic is: -2.2389 3.7382 2.5972 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -4.04 -3.45 -3.15
## phi2  6.50  4.88  4.16
## phi3  8.73  6.49  5.47</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lc.ct)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Ahora bien la hipótesis <span class="math inline">\(\phi_3\)</span> es probada bajo una usual prueba F, es decir, <span class="math inline">\(\phi_3=(a_0,\gamma,a_2) = (a_0,0,0)\)</span>. Esto es, se han colocado restricciones igual a cero a la tendencia temporal y el lag del la variable.</p>
<p>El valor del estadístico es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc.ct<span class="op">@</span>teststat</code></pre></div>
<pre><code>##                tau3     phi2     phi3
## statistic -2.238865 3.738151 2.597211</code></pre>
<p>Debemos recordar que se deben consular los valores críticos propuestas por Dickey and Fuller. Los valores críticos para una muestra de tamaño 100 y niveles de significancia del 10%,5% y 1% se muestran a continuación</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc.ct<span class="op">@</span>cval</code></pre></div>
<pre><code>##       1pct  5pct 10pct
## tau3 -4.04 -3.45 -3.15
## phi2  6.50  4.88  4.16
## phi3  8.73  6.49  5.47</code></pre>
<p>Por lo tanto, la hipótesis nula no puede ser rechazada, lo cual implica que la serie contiene una raíz unitaria. Esto puede ser reiterado con el estadístico <span class="math inline">\(\tau_3\)</span> con valor de -2.24 y para la variable <em>z.lag.1</em>. Los valore críticos relevantes que debemos utilizar ahora son los de Fuller[1976], los cuales se muestran para una muestra de tamaño 100.</p>
<p>Luego entonces, la presencia de una raíz unitaria no puede rechazada. El siguiente paso, es probar si la serie es una caminata aleatoria con o sin drift (constante). El estadístico relevante es <span class="math inline">\(\phi_2\)</span> <span class="math inline">\((\gamma=a_0=a_2=0)\)</span> el cual tiene un valor de 3.74, con valores críticos de 4.16, 4.88 y 6.50 para niveles de significancia de 10%, 5% y 1% respectivamente. La conclusión es entonces que la serie se comporta como una caminata aleatoria pura.</p>
<p>Uno procede entonces a estimar la ecuación <span class="math inline">\(\nabla y_t = a_0 + \gamma y_{t-1} + \epsilon_t\)</span> basado en los resultados obtenidos por la prueba <span class="math inline">\(\phi_3\)</span>. Los resultados se muestran a continuación:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc.co &lt;-<span class="st"> </span><span class="kw">ur.df</span>(lc,<span class="dt">lags=</span><span class="dv">3</span>,<span class="dt">type=</span><span class="st">&#39;drift&#39;</span>)
<span class="kw">summary</span>(lc.co)</code></pre></div>
<pre><code>## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.047547 -0.007071  0.000265  0.007731  0.046880 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  0.0123237  0.0851358   0.145   0.8852  
## z.lag.1     -0.0007356  0.0079043  -0.093   0.9261  
## z.diff.lag1 -0.1433015  0.1016454  -1.410   0.1620  
## z.diff.lag2  0.1615256  0.1020242   1.583   0.1169  
## z.diff.lag3  0.2585280  0.1027364   2.516   0.0136 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01337 on 90 degrees of freedom
## Multiple R-squared:  0.09747,    Adjusted R-squared:  0.05735 
## F-statistic:  2.43 on 4 and 90 DF,  p-value: 0.05335
## 
## 
## Value of test-statistic is: -0.0931 2.8806 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.51 -2.89 -2.58
## phi1  6.70  4.71  3.86</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lc.co)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Con el fin de completar la prueba, ahora se prueba si en este modelo un término constante hace falta. Las pruebas se muestran a continuación</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc.co<span class="op">@</span>teststat</code></pre></div>
<pre><code>##                  tau2     phi1
## statistic -0.09306748 2.880589</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc.co<span class="op">@</span>cval</code></pre></div>
<pre><code>##       1pct  5pct 10pct
## tau2 -3.51 -2.89 -2.58
## phi1  6.70  4.71  3.86</code></pre>
<p>El valor del estadístico <span class="math inline">\(\phi_1\)</span> que prueba <span class="math inline">\(\gamma=a_0=0\)</span> es 2.88, el cual resulta ser no significativo comparado con los valores críticos mostrados.</p>
<p>Por lo tanto, se puede concluir que la serie contiene un raíz unitaria pero no contiene ni tendencia temporal ni tendencia constante en el proceso generador de los datos.</p>
<p>Finalmente, se probará si diferenciando la serie una vez es suficiente para alcanzar estacionariedad. La prueba se logra utilizando como insumo para la regresión a la serie diferenciada una vez.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc2 &lt;-<span class="st"> </span><span class="kw">diff</span>(lc)
lc2.ct &lt;-<span class="st"> </span><span class="kw">ur.df</span>(lc2,<span class="dt">type=</span><span class="st">&quot;trend&quot;</span>,<span class="dt">lags=</span><span class="dv">3</span>)
<span class="kw">summary</span>(lc2.ct)</code></pre></div>
<pre><code>## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.045039 -0.007870  0.000013  0.007807  0.046403 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.864e-03  3.051e-03   1.266   0.2087    
## z.lag.1     -8.826e-01  2.013e-01  -4.385  3.2e-05 ***
## tt           3.186e-05  5.112e-05   0.623   0.5348    
## z.diff.lag1 -2.253e-01  1.873e-01  -1.203   0.2321    
## z.diff.lag2 -4.668e-02  1.600e-01  -0.292   0.7711    
## z.diff.lag3  1.775e-01  1.057e-01   1.679   0.0967 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01329 on 88 degrees of freedom
## Multiple R-squared:  0.6147, Adjusted R-squared:  0.5929 
## F-statistic: 28.08 on 5 and 88 DF,  p-value: &lt; 2.2e-16
## 
## 
## Value of test-statistic is: -4.3853 6.4477 9.6164 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -4.04 -3.45 -3.15
## phi2  6.50  4.88  4.16
## phi3  8.73  6.49  5.47</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc2.ct<span class="op">@</span>teststat</code></pre></div>
<pre><code>##                tau3     phi2     phi3
## statistic -4.385326 6.447681 9.616431</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lc2.ct<span class="op">@</span>cval</code></pre></div>
<pre><code>##       1pct  5pct 10pct
## tau3 -4.04 -3.45 -3.15
## phi2  6.50  4.88  4.16
## phi3  8.73  6.49  5.47</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lc2.ct)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>La hipótesis de que el consumo es <span class="math inline">\(I(2)\)</span> puede ser descartado rápidamente dado el estadístico <span class="math inline">\(t\)</span> con valor de -4.39.</p>
<p>Debe notarse que las pruebas de Dickey-Fuller asumen que los errores son independientes y tienen varianza constante. Esto genera 4 importantes problemas relacionados con el hecho de que no conocemos el verdadero proceso generador de los datos:</p>
<ol style="list-style-type: decimal">
<li>El verdadero proceso generador de los datos puede contener componentes autorregresivas como componentes de promedios móviles</li>
<li>No se puede estimar correctamente <span class="math inline">\(\gamma\)</span> y su error estándar amenos que todos los términos autorregresivos sean incluidos en la ecuación a estimar (seleccionar el lag length apropiado)</li>
<li>El hecho de que la preuba de Dickey-Fuller considera únicamente una raíz unitaria, por lo que llevar una serie de un orden de integración mayor, requeire de diferenciarla tantas veces como sea necesario</li>
<li>No tenemos certeza de si incluir un intercepto o una tendencia temporal a la ecuación</li>
</ol>
<p>El primero de los puntos se resuelve fácilmente ya que un modelo MA invertible (si sus raíces caen fuera del círculo unitario) puede ser expresado en un modelo autorregresivo con lags infinitos. Afortunadamente, Said y Dickey (1984) demuestran que un proceso ARIMA(p,1,q) puede ser correctamente aproximado por un modelo ARIMA(n,1,0) autorregresivo de orden <span class="math inline">\(T^{1/3}\)</span>.</p>
<p>El segundo punto es muy importante ya que incluir demasidos lags reduce el poder de las pruebas estadísticas para rechazar la hipótesis nula de que existe raíz unitara, ya que un mayor número de lags necesita un mayor número de parámetros a estimar y una pérdida en grados de libertad. Los grados de libertad se reducen ya que el número de parámetros a estimar aumenta y por que el número de observaciones utilizables se reduce (perdemos una por cada lag). Por otro lado, definir pocos lags provoca que no capturemos apropiadamente el error process, por lo que <span class="math inline">\(\gamma\)</span> y su error estandar no estarán bien estimados. Para solucionar este tema se sugeire empezar por un número suficientemente grande de lags e ir reduciendo hasta que el i-ésimo lag sea estadísticamente significativo de acuerdo a las preubas <em>t</em>. Una vez que el lag ha sido determinado, se procede a realizar un diagnóstico, graficar los residuales es el diagnóstico más importante. No debe haber evidencia de cambios estructurales ni correlación serial.</p>
<p>El tercer punto se puede atacar de manera secuencial tomando como input la serie diferenciada, y el proceso se repite hasta que se alcance la estacionariedad.</p>
<p>El cuarto punto</p>
<p><a href="https://bookdown.org/ccolonescu/RPoE4/vec-and-var-models.html" class="uri">https://bookdown.org/ccolonescu/RPoE4/vec-and-var-models.html</a></p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="datos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="orden-integracion-pib-a-precios-corrientes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-Orden-de-Integración-Teoria.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
